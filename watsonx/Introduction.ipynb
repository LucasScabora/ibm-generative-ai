{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462733cc-2256-4024-b3c3-d59a7d0046e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .env file: True\n"
     ]
    }
   ],
   "source": [
    "import time, os\n",
    "from dotenv import load_dotenv\n",
    "from genai.credentials import Credentials\n",
    "from genai.model import Model\n",
    "from genai.schemas import GenerateParams, ModelType\n",
    "from genai.extensions.langchain import LangChainInterface\n",
    "#\n",
    "print('Loading .env file:', load_dotenv())\n",
    "api_key = os.getenv('GENAI_KEY', None)\n",
    "api_url = os.getenv('GENAI_API', None)\n",
    "creds = Credentials(api_key, api_endpoint=api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3827c-4ee1-40e4-9cff-d1a402ad253a",
   "metadata": {},
   "source": [
    "# Example (Model Talk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b59058d-d337-4be9-bd06-846499001f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Example (Model Talk)-------------\n",
      "\n",
      "[Alice] --> Hello! How are you?\n",
      "[Bob] --> looking great.\n",
      "[Alice] --> bend down to take them off.\"\n",
      "[Bob] --> bend down to take the shoes off\n",
      "[Alice] --> barefoot , and begin to stuff the cleaning brush into the bottom of the shoe, with the brush in last place. get your brush dry slowly.\n",
      "[Bob] --> If you saved up the brush for a wet day, clean the brush by holding it over a cup and \n",
      "[Alice] --> antacid bottle, stiff side down, and gently rub the tooth brush into the soapy water. You can let the brush air dry, or clean it right away by running lukewarm water over the brush\n",
      "[Bob] --> Turn the bottle upside-down over the toothbrush. Hold the toothbrush at a 45-degree angle to apply the pressure Gent\n",
      "[Alice] --> ly turn the bottle over and place it on a flat surface, such as the table.\n",
      "[Bob] --> 2 Place a wooden ring, such as a dowel, onto one end of the bottle.\n",
      "[Alice] --> 3 Bend the bottle around the index finger wrapped inside the ring.\n",
      "[Bob] --> That’s how long you should cut it into.\n",
      "[Alice] --> 2\n",
      "[Bob] --> on remaining lights after removal of marquee.\n",
      "[Alice] --> Following the closing of the marquee, the lights on the western and southern sides of the House were turned on. After the departure of the politicians, the Democrats stood in line and asked the VP field from a platform\n",
      "[Bob] --> On 21 September 1916, the Broadway marquee was lit by three WBLs along 38th Street and the northern lights (\n",
      "[Alice] --> ) were activated.\n",
      "[Bob] --> Mi accounts for 70% of all Mi-units.\n",
      "[Alice] --> The slick new machine learning algorithms can spot regions that didn’t already have multifactor authentication in place and patch those holes. NOW is also open source!\n",
      "[Bob] --> That’s a win for anyone who wants to punch holes in the easily broken technology.\n",
      "[Alice] --> Just about anyone can get ahold of this software and beat it at their convenience. Doing so could put it out of business. Gas stations, casinos, airlines, schools and banks are all potential targets. However,\n"
     ]
    }
   ],
   "source": [
    "bob_params = GenerateParams(decoding_method=\"sample\", max_new_tokens=25, temperature=1)\n",
    "alice_params = GenerateParams(decoding_method=\"sample\", max_new_tokens=45, temperature=0)\n",
    "bob = Model(ModelType.FLAN_UL2, params=bob_params, credentials=creds)\n",
    "alice = Model(ModelType.FLAN_T5, params=alice_params, credentials=creds)\n",
    "#\n",
    "iter = 0\n",
    "maxiter = 5\n",
    "sentence = \"Hello! How are you?\"\n",
    "#\n",
    "print(f\"[Alice] --> {sentence}\")\n",
    "while iter < maxiter:\n",
    "    bob_response = bob.generate([sentence])\n",
    "    # from first batch get first result generated text\n",
    "    bob_gen = bob_response[0].generated_text\n",
    "    print(f\"[Bob] --> {bob_gen}\")\n",
    "\n",
    "    alice_response = alice.generate([bob_gen])\n",
    "    # from first batch get first result generated text\n",
    "    alice_gen = alice_response[0].generated_text\n",
    "    print(f\"[Alice] --> {alice_gen}\")\n",
    "\n",
    "    sentence = alice_gen\n",
    "    time.sleep(0.5)\n",
    "    iter = 1 + iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2df16-1b43-44c2-99be-0aaa1146504d",
   "metadata": {},
   "source": [
    "# Example (LangChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6cf58c9-e1e9-49f7-8d59-aac1145d6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GenAI Model expressed as LangChain Model via LangChainInterface:\n",
      "Life is the condition of being alive , or the state of being alive , or the fact\n"
     ]
    }
   ],
   "source": [
    "params = GenerateParams(decoding_method=\"greedy\")\n",
    "#\n",
    "print(\"Using GenAI Model expressed as LangChain Model via LangChainInterface:\")\n",
    "#\n",
    "langchain_model = LangChainInterface(model=ModelType.FLAN_UL2,\n",
    "                                     params=params, credentials=creds)\n",
    "print(langchain_model(\"Answer this question: What is life?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
